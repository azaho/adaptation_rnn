{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cbb7ed-3ce3-41a3-86b3-315b3a3bc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json, time, random\n",
    "import hashlib, torch, math, pathlib\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.optimize import curve_fit\n",
    "import importlib, importlib.util, os\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "flexiblenetwork_color = \"#006838\"\n",
    "rigidnetwork_color = \"#97211F\"\n",
    "analyze_network = \"final\"  # options: \"best\", \"final\", <parameter update step no>\n",
    "noise_amplitude = 0.1  # if run analyses with noise, noise amplitude\n",
    "distractor_probability = 1.0\n",
    "distractor_visible = False\n",
    "show_figures = True  # True if running in jupyter notebook; False if running a .py file\n",
    "running_from_data = True # True if code is running in the data folder next to the model.pth. if false, must run from training file\n",
    "task_is = [0, 1]\n",
    "\n",
    "directories = [\n",
    "    f\"data/CTRNN_ROTATION_ra90_nir0_niw0_nrw0.1_ndt0_dr100_la0_tcNR_r0/\",\n",
    "    f\"data/CTRNN_ROTATION_ra90_nir0_niw0_nrw0.1_ndt0_dr100_la0_tcR_r0/\",\n",
    "    f\"data/CTRNN_ROTATION_ra90_nir0_niw0_nrw0.1_ndt0_dr100_la0_tcNR+R_r0/\",\n",
    "]\n",
    "figure_dir_prefix = \"paper_figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1e110a-c201-4c03-a8a7-8c262905b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generalization_figure(resolution = 720):\n",
    "    task_is = np.linspace(-.5, 1.5, 21)\n",
    "    rot_means, rot_sds = [], []\n",
    "    rot_dots = []\n",
    "    \n",
    "    for task_i in task_is:\n",
    "        resolution = resolution\n",
    "        show_distractor = False\n",
    "        noise_amplitude = 0.1\n",
    "        \n",
    "        batch = []  # inputs in the batch\n",
    "        batch_labels = []  # target outputs in the batch\n",
    "        output_masks = []  # masks in the batch\n",
    "        direction1s = []\n",
    "        \n",
    "        for direction1 in np.arange(resolution)/resolution*360:\n",
    "            for direction2 in [0]:\n",
    "                direction1s.append(direction1)\n",
    "                i_full, o_full, b_mask = Task._make_trial(direction1, direction2, delay0, delay1, delay2, 0, show_distractor=show_distractor)\n",
    "                batch.append(i_full.unsqueeze(0))\n",
    "                batch_labels.append(o_full.unsqueeze(0))\n",
    "                output_masks.append(b_mask.unsqueeze(0))\n",
    "        direction1s = np.array(direction1s)\n",
    "        ao_input, ao_target, ao_mask = torch.cat(batch), torch.cat(batch_labels), torch.cat(output_masks)\n",
    "        \n",
    "        _t1 = delay0\n",
    "        _t2 = delay0+task_parameters[\"show_direction_for\"]+delay2\n",
    "        _task_i = task_i\n",
    "        ao_input[:, _t1:_t2, -1] = _task_i\n",
    "        \n",
    "        ao_noise_mask = Task.get_noise_mask(delay0, delay1, delay2)\n",
    "        ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "        ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * noise_amplitude\n",
    "        ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "        \n",
    "        o1_o, o2_o = Task.convert_sincos_to_angles(ao_output, t5, t6)\n",
    "        o1_t, o2_t = Task.convert_sincos_to_angles(ao_target, t5, t6)\n",
    "        \n",
    "        diff = np.abs(np.mean(o1_o.detach().numpy(), axis=1)-direction1s)\n",
    "        diff = np.minimum(diff, np.abs(diff-360))\n",
    "        diff = np.minimum(diff, np.abs(diff+360))\n",
    "        diff = np.mean(o1_o.detach().numpy(), axis=1)-direction1s\n",
    "        diff = np.mean(o1_o.detach().numpy(), axis=1)-np.mean(o1_t.detach().numpy(), axis=1)\n",
    "        diff[diff > 180] -= 360\n",
    "        diff[diff < -180] += 360\n",
    "        rot_means.append(np.mean(diff))\n",
    "        rot_sds.append(np.std(diff))\n",
    "        rot_dots.append(diff)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    plt.rc('font', **{'family': 'Arial', 'weight': 'normal', 'size': 14})\n",
    "    plt.errorbar(task_is, rot_means, rot_sds, ecolor='black', capsize=3, color=\"black\", linewidth=2)\n",
    "    \n",
    "    #for i, task_i in enumerate(task_is):\n",
    "    #    plt.scatter([task_i]*len(rot_dots[i]), rot_dots[i], 3, c=\"gray\")\n",
    "        \n",
    "    plt.fill_between([-.6, -.05], [-90, -90], [180, 180], color=\"gray\", alpha=0.3)\n",
    "    plt.fill_between([1.05, 1.6], [-90, -90], [180, 180], color=\"gray\", alpha=0.3)\n",
    "    \n",
    "    plt.xlabel(\"stimulus\")\n",
    "    plt.ylabel(\"rotation angle (deg)\")\n",
    "    plt.xticks(np.linspace(0, 1, 3))\n",
    "    plt.yticks([-30, 0, 30, 60, 90, 120, 180])\n",
    "    plt.xlim(-.55, 1.55)\n",
    "    plt.ylim(-45, 135)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_dir_prefix+directory[5:-1] + f\"_generalization.pdf\", bbox_inches='tight')\n",
    "\n",
    "def generate_MSD_figure(bandwidth=.1, t_from=0, t_to=-1, t=5, msd_max=0.8):\n",
    "    msd_range = np.linspace(0, msd_max, 100)\n",
    "    energy1, energy2 = generate_MSD_numbers(bandwidth=bandwidth, t_from=t_from, t_to=t_to, t=t, msd_max=msd_max)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.rc('font', **{'family': 'DejaVu Sans', 'weight': 'normal', 'size': 14})\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax1.plot(msd_range, energy1, linewidth=3)\n",
    "    ax2.plot(msd_range, energy2, linewidth=3)\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xlabel(\"MSD\")\n",
    "        ax.set_ylim(-1.5, 2)\n",
    "        ax.set_ylabel(\"Energy\")\n",
    "    ax1.set_title(\"no rotation\")\n",
    "    ax2.set_title(\"rotation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_MSD_numbers(bandwidth=.1, t_from=0, t_to=-1, t=5, msd_max=0.8):\n",
    "    def energy_msd_dt(signal, t, msd_range, bandwidth=bandwidth):  # time range in dt\n",
    "        res = np.zeros((len(msd_range), ))\n",
    "        if len(signal.shape)==3: # n_trials x n_timesteps x n_neurons\n",
    "            squared_displacement = 2*torch.mean((signal[:, t:]-signal[:, :-t]) ** 2, dim=[1, 2])**0.5\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(squared_displacement.reshape(-1, 1))\n",
    "        scores = -kde.score_samples(msd_range.reshape(-1, 1))\n",
    "        res[:] = scores\n",
    "        return res\n",
    "\n",
    "    dt=1\n",
    "    data1 = ao_output[:, t_from:t_to].reshape(2, -1, t_to-t_from, 2)[0]\n",
    "    data2 = ao_output[:, t_from:t_to].reshape(2, -1, t_to-t_from, 2)[1]\n",
    "    data1 = data1 / (torch.sum(data1**2, dim=2)**0.5).unsqueeze(2)\n",
    "    data2 = data2 / (torch.sum(data2**2, dim=2)**0.5).unsqueeze(2)\n",
    "    \n",
    "    msd_range = np.linspace(0, msd_max, 100)\n",
    "    energy1 = energy_msd_dt(data1, t, msd_range)\n",
    "    energy2 = energy_msd_dt(data2, t, msd_range)\n",
    "    \n",
    "    return energy1, energy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0f5836-7243-41f9-ac00-a8f680b37213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CTRNN_ROTATION_ra90_nir0_niw0_nrw0.1_ndt0_dr100_la0_tcNR_r0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--net_size NET_SIZE] [--random RANDOM]\n",
      "                             [--init INIT]\n",
      "                             [--rotation_degrees ROTATION_DEGREES]\n",
      "                             [--noise_inputrelevant NOISE_INPUTRELEVANT]\n",
      "                             [--noise_recurrentwhite NOISE_RECURRENTWHITE]\n",
      "                             [--noise_inputwhite NOISE_INPUTWHITE]\n",
      "                             [--noise_delaytime NOISE_DELAYTIME]\n",
      "                             [--distractor_visible DISTRACTOR_VISIBLE]\n",
      "                             [--training_condition TRAINING_CONDITION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/andrewzahorodnii/Library/Jupyter/runtime/kernel-e3d3c98e-96eb-4342-9d97-35021bd820d0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3259: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "for _directory in directories:\n",
    "    print(_directory)\n",
    "    directory = _directory\n",
    "    \n",
    "    # Define the file path and module name\n",
    "    file_path = directory + \"task_and_training.py\"  # Change this to your file's path\n",
    "    module_name = 'task_and_training'  # Arbitrary name for the module\n",
    "    # Create a module object\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    # Load the module into memory and execute it\n",
    "    spec.loader.exec_module(module)\n",
    "    # Inject attributes into the global namespace\n",
    "    for attr in dir(module):\n",
    "        globals()[attr] = getattr(module, attr)\n",
    "    directory = _directory  # it might have been changed by the imported file, so change it back\n",
    "    \n",
    "    with open(directory+f\"info.json\", 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "    hyperparameters = j[\"hyperparameters\"]\n",
    "    task_parameters = j[\"task_parameters\"]\n",
    "    model_parameters = j[\"model_parameters\"]\n",
    "    additional_comments = j[\"additional_comments\"]\n",
    "    directory = j[\"directory\"]\n",
    "    figures_directory=\"figures/\"\n",
    "    pathlib.Path(figures_directory+\"a.a\").parent.mkdir(parents=True, exist_ok=True)\n",
    "    def save_figure(figure_name):\n",
    "        plt.savefig(figures_directory+figure_name+\".pdf\")\n",
    "        if show_figures: \n",
    "            plt.show()\n",
    "        \n",
    "    # some noise may be necessary to prevent dividing by 0 in some of the analyses\n",
    "    # if noise_amplitude == 0: noise_amplitude = 0.0001\n",
    "        \n",
    "    model = Model()\n",
    "    if analyze_network.lower() == \"best\": network_filename = \"model_best.pth\"\n",
    "    elif analyze_network.lower() == \"final\": network_filename = f\"model_parameterupdate{hyperparameters['train_for_steps']}.pth\"\n",
    "    else: network_filename = f\"model_parameterupdate{analyze_network}.pth\"\n",
    "    model_state_dict = torch.load(directory+network_filename, map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    ORI_RES = 360/8\n",
    "    ORI_SET = torch.arange(0, 360, ORI_RES)\n",
    "    ORI_SET_SIZE = ORI_SET.shape[0]\n",
    "    \n",
    "    # fix delays at median values for analysis\n",
    "    delay0, delay1, delay2 = Task.get_median_delays()\n",
    "    show_direction_for = task_parameters[\"show_direction_for\"]\n",
    "    show_cue_for = task_parameters[\"show_cue_for\"]\n",
    "    total_time = show_direction_for+show_cue_for+delay0+delay2\n",
    "    t1, t1d = delay0, \"before O1 presented\"\n",
    "    t1_5, t1_5d = delay0+show_direction_for//2, \"amid 01 presentation\"\n",
    "    t2, t2d = delay0+show_direction_for, \"after O1 presented\"\n",
    "    t3, t3d = delay0+show_direction_for+delay1, \"before O2 presented\"\n",
    "    t3_5, t3_5d = delay0+show_direction_for+delay1+show_direction_for//2, \"amid O2 presentation\"\n",
    "    t4, t4d = delay0+show_direction_for+delay1+show_direction_for, \"after O2 presented\"\n",
    "    t5, t5d = delay0+show_direction_for+delay2, \"before go cue\"\n",
    "    t6, t6d = total_time-1, \"at end of task\"\n",
    "    \n",
    "    # run the model on all possible directions \n",
    "    def make_all_integer_directions_batch(delay0, delay1, delay2, resolution=360//ORI_RES, show_distractor=True):\n",
    "        batch = []  # inputs in the batch\n",
    "        batch_labels = []  # target outputs in the batch\n",
    "        output_masks = []  # masks in the batch\n",
    "        for task_i in task_is:\n",
    "            for direction1 in np.arange(resolution)/resolution*360:\n",
    "                for direction2 in np.arange(resolution)/resolution*360:\n",
    "                    i_full, o_full, b_mask = Task._make_trial(direction1, direction2, delay0, delay1, delay2, task_i, show_distractor=show_distractor)\n",
    "                    batch.append(i_full.unsqueeze(0))\n",
    "                    batch_labels.append(o_full.unsqueeze(0))\n",
    "                    output_masks.append(b_mask.unsqueeze(0))\n",
    "        return torch.cat(batch), torch.cat(batch_labels), torch.cat(output_masks)\n",
    "    ao_input, ao_target, ao_mask = make_all_integer_directions_batch(delay0, delay1, delay2, show_distractor=distractor_visible)\n",
    "    ao_noise_mask = Task.get_noise_mask(delay0, delay1, delay2)\n",
    "    ao_noise_mask = ao_noise_mask.repeat(ao_input.shape[0], 1).unsqueeze(2).repeat(1, 1, model.dim_recurrent)  # convert to (batch_size, total_time, dim_recurrent)\n",
    "    ao_noise = torch.randn_like(ao_noise_mask) * ao_noise_mask * noise_amplitude\n",
    "    ao_output, ao_h = model.forward(ao_input, noise=ao_noise)\n",
    "    \n",
    "    # output model errors (with noise and without)\n",
    "    mse_o1, mse_o2, err_o1, err_o2 = Task.calculate_errors(ao_target, ao_output, ao_mask, t5, t6)\n",
    "    ao_output_nn, ao_h_nn = model.forward(ao_input, noise=ao_noise*0)\n",
    "    mse_o1_nn, mse_o2_nn, err_o1_nn, err_o2_nn = Task.calculate_errors(ao_target, ao_output_nn, ao_mask, t5, t6)\n",
    "    \n",
    "    # for every timestep and every unit, calculate its activity in all trials\n",
    "    ao_data = torch.zeros((2, total_time, model.dim_recurrent, ORI_SET_SIZE, ORI_SET_SIZE))\n",
    "    for task_i in task_is:\n",
    "        for direction1 in range(ORI_SET_SIZE):\n",
    "            for direction2 in range(ORI_SET_SIZE):\n",
    "                o = ao_h[task_i * ORI_SET_SIZE**2 + direction1 * ORI_SET_SIZE + direction2]\n",
    "                ao_data[task_i][:, :, direction1, direction2] = o\n",
    "            \n",
    "    # detach from autograd\n",
    "    ao_output = ao_output.detach()\n",
    "    ao_h = ao_h.detach()\n",
    "    ao_data = ao_data.detach()\n",
    "\n",
    "    ################################################\n",
    "\n",
    "    #generate_generalization_figure(resolution = 30)\n",
    "    generate_MSD_figure(bandwidth=.1, t_from=t1, t_to=t5, t=5, msd_max=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f1fb3-e0ef-4404-9372-52fe2b7160f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
